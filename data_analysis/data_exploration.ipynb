{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure settings for visualizations\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the working directory\n",
    "os.chdir('/Users/kr24945/Documents/Projects/Materia science/ML4Polymers/ML4Polymers')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PromptAndPolyNCPrediction.csv']\n",
      "['Tg_val_SMILES.csv', 'data_with_descriptors.csv', 'ml_predictions.csv']\n",
      "['prompt-target-cls-pred.csv', 'prompt-target-pred.csv', 'prompt-target.csv', 'aug_bandgap-crystal.csv', 'pred-Tg.csv', 'aug_atomization energy.csv', 'bandgap-crystal.csv', 'propm-atomization energy.csv', 'pred-bandgap crystal.csv', 'aug_Tg_with_descriptors.csv', 'pred-atomization energy.csv', 'prompt-target-reg-pred.csv', 'propm-polyimide_cls.csv', 'atomization energy.csv', 'propm-bandgap crystal.csv', 'aug_Tg.csv', 'propm-Tg.csv', 'polyimide_cls.csv', 'Tg-all.csv', 'aug_polyimide_cls.csv']\n",
      "['merged_date_with_descriptors_filtered_data.csv', 'merged_date_with_descriptors_cleaned.csv', 'GCN-reg-test.csv', 'GCN-cls-test.csv']\n",
      "['prompt-target.csv', 'aug_bandgap-crystal.csv', 'aug_atomization energy.csv', 'aug_Tg-all.csv', 'bandgap-crystal.csv', 'propm-atomization energy.csv', 'propm-polyimide_cls.csv', 'atomization energy.csv', 'propm-bandgap crystal.csv', 'propm-Tg.csv', 'polyimide_cls.csv', 'Tg-all.csv', 'aug_polyimide_cls.csv']\n",
      "['merged_date_with_descriptors_filtered_data.csv', 'merged_data.csv', 'GCN-cls-train.csv', 'GCN-reg-train.csv']\n"
     ]
    }
   ],
   "source": [
    "# Path to the subdirectory\n",
    "subdirectory1 = 'data/'\n",
    "subdirectory2 = 'data/exp_val'\n",
    "subdirectory3 = 'data/test/'\n",
    "subdirectory3a = 'data/test/merge/'\n",
    "subdirectory4 = 'data/train'\n",
    "subdirectory4a = 'data/train/merge'\n",
    "\n",
    "# List all CSV files in the subdirectory\n",
    "csv_files1 = [f for f in os.listdir(subdirectory1) if f.endswith('.csv')]\n",
    "csv_files2 = [f for f in os.listdir(subdirectory2) if f.endswith('.csv')]\n",
    "csv_files3 = [f for f in os.listdir(subdirectory3) if f.endswith('.csv')]\n",
    "csv_files3a = [f for f in os.listdir(subdirectory3a) if f.endswith('.csv')]\n",
    "csv_files4 = [f for f in os.listdir(subdirectory4) if f.endswith('.csv')]\n",
    "csv_files4a = [f for f in os.listdir(subdirectory4a) if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files1)\n",
    "print(csv_files2)\n",
    "print(csv_files3)\n",
    "print(csv_files3a)\n",
    "print(csv_files4)\n",
    "print(csv_files4a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hn/yy0f4gf550d1fb7rsdb9wszm0000gp/T/ipykernel_4290/106860271.py:35: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_dict[key_name] = pd.read_csv(os.path.join(subdirectory, file_name))\n",
      "/var/folders/hn/yy0f4gf550d1fb7rsdb9wszm0000gp/T/ipykernel_4290/106860271.py:35: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_dict[key_name] = pd.read_csv(os.path.join(subdirectory, file_name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrames: dict_keys(['promptandpolyncprediction', 'tg_val_smiles', 'data_with_descriptors', 'ml_predictions', 'prompt_target_cls_pred', 'prompt_target_pred', 'prompt_target', 'aug_bandgap_crystal', 'pred_tg', 'aug_atomization_energy', 'bandgap_crystal', 'propm_atomization_energy', 'pred_bandgap_crystal', 'aug_tg_with_descriptors', 'pred_atomization_energy', 'prompt_target_reg_pred', 'propm_polyimide_cls', 'atomization_energy', 'propm_bandgap_crystal', 'aug_tg', 'propm_tg', 'polyimide_cls', 'tg_all', 'aug_polyimide_cls', 'merged_date_with_descriptors_filtered_data', 'merged_date_with_descriptors_cleaned', 'gcn_reg_test', 'gcn_cls_test', 'aug_tg_all', 'merged_data', 'gcn_cls_train', 'gcn_reg_train'])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the subdirectory paths\n",
    "subdirectory1 = 'data/'\n",
    "subdirectory2 = 'data/exp_val/'\n",
    "subdirectory3 = 'data/test/'\n",
    "subdirectory3a = 'data/test/merge/'\n",
    "subdirectory4 = 'data/train/'\n",
    "subdirectory4a = 'data/train/merge/'\n",
    "\n",
    "# Function to clean up file names for dictionary keys (optional)\n",
    "def clean_filename(filename):\n",
    "    return filename.replace('.csv', '').replace('-', '_').replace(' ', '_').lower()\n",
    "\n",
    "# Load the CSV files from each subdirectory into a dictionary\n",
    "data_dict = {}\n",
    "\n",
    "# List of all subdirectories and corresponding file lists\n",
    "subdirectories = [\n",
    "    (subdirectory1, csv_files1),\n",
    "    (subdirectory2, csv_files2),\n",
    "    (subdirectory3, csv_files3),\n",
    "    (subdirectory3a, csv_files3a),\n",
    "    (subdirectory4, csv_files4),\n",
    "    (subdirectory4a, csv_files4a)\n",
    "]\n",
    "\n",
    "# Load the CSV files into the dictionary\n",
    "for subdirectory, file_list in subdirectories:\n",
    "    for file_name in file_list:\n",
    "        # Create a cleaned-up version of the file name for the key\n",
    "        key_name = clean_filename(file_name)\n",
    "        # Load the DataFrame and store it in the dictionary\n",
    "        data_dict[key_name] = pd.read_csv(os.path.join(subdirectory, file_name))\n",
    "\n",
    "# Display the dictionary keys to verify the loading\n",
    "print(\"Loaded DataFrames:\", data_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in data_dict.items():\n",
    "    print(f\"DataFrame for {name}:\")\n",
    "    print(df.head(), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data clearing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: promptandpolyncprediction\n",
      "DataFrame 1:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dfs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'head'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polyNC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
